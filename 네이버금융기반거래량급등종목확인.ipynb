{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 간단한 웹 스크레이핑으로 거래량 급등 종목 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오늘 오른게 내일은 오를지 떨어질지는 아무도 모릅니다.\n",
    "\n",
    "매튜 맥커너히 형님이 말씀하셨죠.\n",
    "\n",
    "하지만 뭐 거래량 급등하는 종목들을 매일매일 확인하다보면 뭔가 insight가 생기지 않을까요\n",
    "\n",
    "지금 당장 생각나는게 작전주 파악이네요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 먼저 네이버 금융을 불러오고, 페이지를 soup 합니다\n",
    "\n",
    "페이지를 soup하면서 파이썬이 HTML을 읽을 수 있게된다고 생각하면 됩니다.\n",
    "\n",
    "물론 정확한 좌표를 지정을 본인이 해줘야합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "source = \"http://finance.naver.com/sise/sise_upper.nhn\"\n",
    "\n",
    "uClient = uReq(source)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "page_soup = soup(page_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주식의 이름을 가져옵니다\n",
    "\n",
    "좌표를 가지고오고, 필요없는 HTML을 지워줍니다. \n",
    "\n",
    "이건 2018년에 제가 처음 스크레이핑 할 때라, 좌표를 정말 잘 못찾던 때이군요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이디\n",
      "팬스타엔터프라이즈\n",
      "['이디', '팬스타엔터프라이즈']\n"
     ]
    }
   ],
   "source": [
    "name_containers = page_soup.findAll(\"td\",{\"style\":\"padding-left:15px;\"})\n",
    "\n",
    "name_list = []\n",
    "for contain in name_containers:\n",
    "    text_container = contain.findAll(\"a\")\n",
    "    line = str(text_container)\n",
    "    clean_line1 = line[:-5]\n",
    "    clean_line2 = clean_line1[38:]\n",
    "    print(clean_line2)\n",
    "    name_list.append(clean_line2)\n",
    "    \n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고가 검색을 합니다\n",
    "\n",
    "전일 대비 얼마나 올랐는지 확인해 봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "257\n",
      "['164', '257']\n"
     ]
    }
   ],
   "source": [
    "cont_containers = page_soup.findAll(\"span\",{\"class\":\"tah p11 red02\"})\n",
    "\n",
    "up_list = []\n",
    "for contain in cont_containers:\n",
    "    line = str(contain)\n",
    "    clean_line1 = line[:-7]\n",
    "    clean_line2 = clean_line1[28:]\n",
    "    print(clean_line2.strip())\n",
    "    up_list.append(clean_line2.strip())\n",
    "\n",
    "print(up_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 등락률을 계산합니다\n",
    "\n",
    "퍼센트 있으면 멋져보이자나요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+29.98%\n",
      "+29.44%\n",
      "['+29.98%', '+29.44%']\n"
     ]
    }
   ],
   "source": [
    "rate_containers = page_soup.findAll(\"span\",{\"class\":\"tah p11 red01\"})\n",
    "\n",
    "rate_list = []\n",
    "for contain in rate_containers:\n",
    "    line = str(contain)\n",
    "    clean_line1 = line[:-7]\n",
    "    clean_line2 = clean_line1[28:]\n",
    "    print(clean_line2.strip())\n",
    "    rate_list.append(clean_line2.strip())\n",
    "\n",
    "print(rate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비서에게 보고 받는것 처럼 뽑아 봅시다\n",
    "\n",
    "서울경제나 뭐 카카오 스탁 같은 곳에서 로봇 뉴스하는게 이거랑 원리는 똑같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금일 이디 - 전일대비 164 원 상승했으며, 등락률은 +29.98% 입니다 \n",
      "\n",
      "금일 팬스타엔터프라이즈 - 전일대비 257 원 상승했으며, 등락률은 +29.44% 입니다 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "comb_list = list(zip(name_list, up_list, rate_list))\n",
    "\n",
    "for i,j,k in comb_list:\n",
    "    print(\"금일 %s - 전일대비 %s 원 상승했으며, 등락률은 %s 입니다 \\n\" % (i,j,k) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 더 개발해 보고 싶은 욕심"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 매일매일 하루가 끝날 때 마다 자동으로 정리하고 보고를 pandas Dataframe에다가 저장해두는게 최고지\n",
    "2. 하루가 끝날 때가 아니라 주식 API랑 연동해서 시간별 보고를 받는게 최고다\n",
    "3. 해당 주식 종목코드를 찾아서 관련 뉴스도 scrape한담에 보고서 형식으로 올라가면 그것도 좋은 add-on 이다\n",
    "4. 데이터의 끝은 예측이니... 올라갈꺼 예측도... \n",
    "5. GUI가 있으면 Bloomberg 부럽지 않은 터미널이... 읍읍읍...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 굳이 내가 해야하나\n",
    "\n",
    "내가 주식을 많이 좋아하면 하겠는데 나는 data에 관심있을 뿐 주식동향을 알아야 한다는 motive는 없다...\n",
    "\n",
    "주식을 할 거면 큰 기업에 넣고, 오래 보는게 답아니겠습니까."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
